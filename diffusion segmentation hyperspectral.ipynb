{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU Name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if PyTorch recognizes the GPU\n",
    "print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_dir': 'pixel_classifiers/Berlin_benchmark/datasetDDPM', 'model_type': 'ddpm', 'category': 'Berlin_benchmark', 'number_class': 8, 'ignore_label': 0, 'bands_num': 244, 'training_path': 'datasets/Berlin_benchmark/Berlin_benchmark_train_data_32', 'testing_path': 'datasets/Berlin_benchmark/Berlin_benchmark_test_data_32', 'train_data_pt_folder': 'datasets/Berlin_benchmark/', 'test_label_calculate_metric': 'datasets/Berlin_benchmark/test_label_berlin.npy', 'model_path': 'checkpoints/ddpm/64x64_diffusion.pt', 'dim': [64, 64, 384], 'steps': [50], 'blocks': [11], 'model_num': 1, 'batch_size': 64, 'max_training': 30, 'learning_rate': 0.003, 'max_epoch': 10, 'model_name': 'pixelclassfier', 'mix_up_alpha': 0.2, 'lam_spatial_weight': 0.5, 'lam_spectral_weight': 0.5, 'training_number': 742, 'testing_number': 742, 'deeplab_res': 64, 'upsample_mode': 'bilinear', 'share_noise': True, 'input_activations': False, 'img_width_orig': 476, 'img_height_orig': 1723, 'img_width_adjusted': 480, 'img_height_adjusted': 1728}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON to inspect the structure\n",
    "with open('experiments/Berlin_benchmark/datasetDDPM.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the 'steps' value\n",
    "data['exp_dir'] = 'GeodiffNet/Berlin_benchmark' # Replace 'new_value' with your desired steps\n",
    "#data['steps'] = [50]  # Replace 'new_value' with your desired steps\n",
    "#data['max_training'] = 30\n",
    "#data['max_epoch'] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified JSON data: {'exp_dir': 'GeodiffNet/Berlin_benchmark', 'model_type': 'ddpm', 'category': 'Berlin_benchmark', 'number_class': 8, 'ignore_label': 0, 'bands_num': 244, 'training_path': 'datasets/Berlin_benchmark/Berlin_benchmark_train_data_32', 'testing_path': 'datasets/Berlin_benchmark/Berlin_benchmark_test_data_32', 'train_data_pt_folder': 'datasets/Berlin_benchmark/', 'test_label_calculate_metric': 'datasets/Berlin_benchmark/test_label_berlin.npy', 'model_path': 'checkpoints/ddpm/64x64_diffusion.pt', 'dim': [64, 64, 384], 'steps': [50], 'blocks': [11], 'model_num': 1, 'batch_size': 64, 'max_training': 30, 'learning_rate': 0.003, 'max_epoch': 10, 'model_name': 'pixelclassfier', 'mix_up_alpha': 0.2, 'lam_spatial_weight': 0.5, 'lam_spectral_weight': 0.5, 'training_number': 742, 'testing_number': 742, 'deeplab_res': 64, 'upsample_mode': 'bilinear', 'share_noise': True, 'input_activations': False, 'img_width_orig': 476, 'img_height_orig': 1723, 'img_width_adjusted': 480, 'img_height_adjusted': 1728}\n"
     ]
    }
   ],
   "source": [
    "# Save the modified JSON back to the file\n",
    "with open('experiments/Berlin_benchmark/datasetDDPM.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4)\n",
    "\n",
    "print(\"Modified JSON data:\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCbgTXG2eFys"
   },
   "source": [
    "# Hyperspectral Berlin Benchmark Dataset(using pre-trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gxmSDPryeNAu"
   },
   "outputs": [],
   "source": [
    "MODEL_FLAGS=\"--attention_resolutions 32,16,8 --class_cond True --diffusion_steps 1000 --dropout 0.1 --image_size 64 --learn_sigma True --noise_schedule cosine --num_channels 192 --num_head_channels 64 --num_res_blocks 3 --resblock_updown True --use_new_attention_order True --use_fp16 True --use_scale_shift_norm True\"\n",
    "#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241917,
     "status": "ok",
     "timestamp": 1721045415863,
     "user": {
      "displayName": "Yuzhen Hu",
      "userId": "09747670991557252235"
     },
     "user_tz": 300
    },
    "id": "TQ4eFqNAePP1",
    "outputId": "67880878-f1aa-4fc4-af8b-27abcce4e936",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run train.py --exp experiments/Berlin_benchmark/datasetDDPM.json $MODEL_FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cKofUbcebaM"
   },
   "source": [
    "# Hyperspectral Augsburg Dataset (using pre-trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZJNjbu8QejQd"
   },
   "outputs": [],
   "source": [
    "MODEL_FLAGS=\"--attention_resolutions 32,16,8 --class_cond True --diffusion_steps 1000 --dropout 0.1 --image_size 64 --learn_sigma True --noise_schedule cosine --num_channels 192 --num_head_channels 64 --num_res_blocks 3 --resblock_updown True --use_new_attention_order True --use_fp16 True --use_scale_shift_norm True\"\n",
    "#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "executionInfo": {
     "elapsed": 3907,
     "status": "ok",
     "timestamp": 1721260488906,
     "user": {
      "displayName": "hutuhehe",
      "userId": "18298293410951222141"
     },
     "user_tz": 300
    },
    "id": "shDKBdCIehLW",
    "outputId": "2dd23100-be0e-47c3-d87d-62dcfd91a31b"
   },
   "outputs": [],
   "source": [
    "\n",
    "%run train.py --exp experiments/Augsburg_Benchmark/datasetDDPM.json $MODEL_FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEPAtByGlSy8"
   },
   "source": [
    "# hyperspectral UH dataset(64by 64model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DDlZ1Gb2W9q"
   },
   "outputs": [],
   "source": [
    "MODEL_FLAGS=\"--attention_resolutions 32,16,8 --class_cond True --diffusion_steps 1000 --dropout 0.1 --image_size 64 --learn_sigma True --noise_schedule cosine --num_channels 192 --num_head_channels 64 --num_res_blocks 3 --resblock_updown True --use_new_attention_order True --use_fp16 True --use_scale_shift_norm True\"\n",
    "#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ro0gYLoWmgO3"
   },
   "outputs": [],
   "source": [
    "%run train_qkv_berlin.py --exp experiments/berlin_64_stride_32/datasetDDPM.json $MODEL_FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXObgMChuszk"
   },
   "source": [
    "put jpg patches into one big mask label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune diffusion model (with Augsubrug RGB)\n",
    "https://github.com/openai/improved-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FLAGS=\"--attention_resolutions 32,16,8 --class_cond True --diffusion_steps 1000 --dropout 0.1 --image_size 64 --learn_sigma True --noise_schedule cosine --num_channels 192 --num_head_channels 64 --num_res_blocks 3 --resblock_updown True --use_new_attention_order True --use_fp16 True --use_scale_shift_norm True\"\n",
    "#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS\n",
    "TRAIN_FLAGS=\"--lr 1e-3 --batch_size 32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU detected. Using local GPU without distributed setup.\n",
      "Logging to C:\\Users\\hyz20\\AppData\\Local\\Temp\\openai-2024-10-07-22-53-39-320393\n",
      "creating model and diffusion...\n",
      "Loading pre-trained model from checkpoints/ddpm/64x64_diffusion.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\one_pixel_two_features\\image_train.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(pretrained_model_path, map_location=dist_util.dev()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name: input_blocks.5.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.5.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.6.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.6.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.7.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.7.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.9.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.9.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.10.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.10.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.11.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.11.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.13.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.13.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.14.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.14.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.15.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: input_blocks.15.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: middle_block.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: middle_block.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.0.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.0.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.1.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.1.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.2.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.2.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.3.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 2304, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.3.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.4.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.4.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.5.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.5.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.6.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.6.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.7.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 1728, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.7.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(576, 576, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.8.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.8.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.9.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.9.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.10.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.10.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.11.1.qkv\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "Layer name: output_blocks.11.1.proj_out\n",
      "Conv1d(\n",
      "  (conv): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      ")\n",
      "\n",
      "creating data loader...\n",
      "training...\n",
      "loading data\n",
      "----------------------------\n",
      "| grad_norm     | 0.00193  |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 0.137    |\n",
      "| loss_q0       | 0.249    |\n",
      "| loss_q1       | 0.131    |\n",
      "| loss_q2       | 0.0606   |\n",
      "| loss_q3       | 0.00869  |\n",
      "| mse           | 0.135    |\n",
      "| mse_q0        | 0.245    |\n",
      "| mse_q1        | 0.131    |\n",
      "| mse_q2        | 0.0603   |\n",
      "| mse_q3        | 0.00855  |\n",
      "| param_norm    | 2.09e+03 |\n",
      "| samples       | 32       |\n",
      "| step          | 0        |\n",
      "| vb            | 0.00163  |\n",
      "| vb_q0         | 0.00424  |\n",
      "| vb_q1         | 0.000663 |\n",
      "| vb_q2         | 0.000305 |\n",
      "| vb_q3         | 0.000145 |\n",
      "----------------------------\n",
      "saving model 0...\n",
      "> \u001b[1;32md:\\one_pixel_two_features\\guided_diffusion\\guided_diffusion\\train_util.py\u001b[0m(252)\u001b[0;36msave_checkpoint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    250 \u001b[1;33m            \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"saving model {rate}...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    251 \u001b[1;33m            \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 252 \u001b[1;33m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    253 \u001b[1;33m                \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"model{(self.step+self.resume_step):06d}.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    254 \u001b[1;33m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32md:\\one_pixel_two_features\\guided_diffusion\\guided_diffusion\\train_util.py\u001b[0m(253)\u001b[0;36msave_checkpoint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    251 \u001b[1;33m            \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    252 \u001b[1;33m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 253 \u001b[1;33m                \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"model{(self.step+self.resume_step):06d}.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    254 \u001b[1;33m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    255 \u001b[1;33m                \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"ema_{rate}_{(self.step+self.resume_step):06d}.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32md:\\one_pixel_two_features\\guided_diffusion\\guided_diffusion\\train_util.py\u001b[0m(256)\u001b[0;36msave_checkpoint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    254 \u001b[1;33m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    255 \u001b[1;33m                \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"ema_{rate}_{(self.step+self.resume_step):06d}.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 256 \u001b[1;33m            \u001b[1;32mwith\u001b[0m \u001b[0mbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBlobFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_blob_logdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    257 \u001b[1;33m                \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    258 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  filename\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model000000.pt'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  get_blob_logdir()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C:\\\\Users\\\\hyz20\\\\AppData\\\\Local\\\\Temp\\\\openai-2024-10-07-22-53-39-320393'\n"
     ]
    }
   ],
   "source": [
    "%run image_train.py --data_dir data\n",
    "sets/Augsburg_benchmark/Augsburg_RGB $MODEL_FLAGS  $TRAIN_FLAGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FLAGS=\"--image_size 64 --num_channels 128 --num_res_blocks 3\"\n",
    "DIFFUSION_FLAGS=\"--diffusion_steps 4000 --noise_schedule linear\"\n",
    "TRAIN_FLAGS=\"--lr 1e-4 --batch_size 128\"\n",
    "#PATH = '--pretrained_model_path checkpoints/ddpm/64x64_diffusion.pt'\n",
    "#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1QmclmJ9benW2-MeVXYJfGe-RCR6qUQOo",
     "timestamp": 1709946631359
    },
    {
     "file_id": "1N_NOVWZlImob2x6qKd0lXMtSKwuW6eWz",
     "timestamp": 1707018897318
    },
    {
     "file_id": "1kNeGtPvEuPTvbOgji51Wavp9x6K5RJzS",
     "timestamp": 1706151817039
    }
   ]
  },
  "kernelspec": {
   "display_name": "GPU Environment",
   "language": "python",
   "name": "gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
