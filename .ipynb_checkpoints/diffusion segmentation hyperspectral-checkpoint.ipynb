{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8097,"status":"ok","timestamp":1724946812792,"user":{"displayName":"hutuhehe","userId":"18298293410951222141"},"user_tz":300},"id":"mvsDHlxKhkab","outputId":"4c631fc6-e98a-42fe-a591-3222b8590530"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1721260072098,"user":{"displayName":"hutuhehe","userId":"18298293410951222141"},"user_tz":300},"id":"Xdm6KCFsrC9t","outputId":"39450903-64cf-445f-8259-21e9eae4a704"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/diffusion_segmentation/ddpm-segmentation\n"]}],"source":["%cd '/content/drive/MyDrive/diffusion_segmentation/ddpm-segmentation/'"]},{"cell_type":"markdown","metadata":{"id":"qclZe5f9bfnU"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2ClLIwq7ZAd","outputId":"af96cf7b-b5a7-4d10-aad4-7ef15ef04cd8","executionInfo":{"status":"ok","timestamp":1721260134907,"user_tz":300,"elapsed":61256,"user":{"displayName":"hutuhehe","userId":"18298293410951222141"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mpi4py\n","  Downloading mpi4py-3.1.6.tar.gz (2.4 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mpi4py\n","  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.6-cp310-cp310-linux_x86_64.whl size=2746306 sha256=e2edcaf987bbaa73b18718bfc2bf7bbfe159a99f5c6ec133979e2f4bef566af3\n","  Stored in directory: /root/.cache/pip/wheels/4c/ca/89/8fc1fb1c620afca13bb41c630b1f948bbf446e0aaa4b762e10\n","Successfully built mpi4py\n","Installing collected packages: mpi4py\n","Successfully installed mpi4py-3.1.6\n"]}],"source":["pip install mpi4py"]},{"cell_type":"markdown","metadata":{"id":"twEZH6jjATLr"},"source":["Setting hyperparameter"]},{"cell_type":"markdown","metadata":{"id":"KmpMXPW1AWY8"},"source":[]},{"cell_type":"markdown","metadata":{"id":"8rJcLPsXMaro"},"source":["Download dataset by running cifar10.py"]},{"cell_type":"markdown","metadata":{"id":"fSNdnc3RMl26"},"source":["parse training data directory to --data dir, and  parse hyperparameter to image_train.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6992,"status":"ok","timestamp":1721260257904,"user":{"displayName":"hutuhehe","userId":"18298293410951222141"},"user_tz":300},"id":"N49abxoD9yg5","outputId":"64e8ded8-c558-416f-cfdb-5834d1fe1ed4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting blobfile\n","  Downloading blobfile-2.1.1-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pycryptodomex~=3.8 (from blobfile)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile) (2.0.7)\n","Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile) (4.9.4)\n","Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.10/dist-packages (from blobfile) (3.15.4)\n","Installing collected packages: pycryptodomex, blobfile\n","Successfully installed blobfile-2.1.1 pycryptodomex-3.20.0\n"]}],"source":["!pip install blobfile"]},{"cell_type":"markdown","metadata":{"id":"SCbgTXG2eFys"},"source":["# Hyperspectral Berlin Benchmark Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxmSDPryeNAu"},"outputs":[],"source":["MODEL_FLAGS=\"--attention_resolutions 32,16,8 --class_cond True --diffusion_steps 1000 --dropout 0.1 --image_size 64 --learn_sigma True --noise_schedule cosine --num_channels 192 --num_head_channels 64 --num_res_blocks 3 --resblock_updown True --use_new_attention_order True --use_fp16 True --use_scale_shift_norm True\"\n","#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241917,"status":"ok","timestamp":1721045415863,"user":{"displayName":"Yuzhen Hu","userId":"09747670991557252235"},"user_tz":300},"id":"TQ4eFqNAePP1","outputId":"67880878-f1aa-4fc4-af8b-27abcce4e936"},"outputs":[{"output_type":"stream","name":"stdout","text":["> \u001b[0;32m/content/drive/.shortcut-targets-by-id/1kM6vOx8unEcGbzN3nwcZDA1phB8UHd8_/diffusion_segmentation/ddpm-segmentation/train_qkv_berlin.py\u001b[0m(338)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m    336 \u001b[0;31m    \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    337 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m--> 338 \u001b[0;31m    \u001b[0madd_dict_to_argparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_and_diffusion_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    339 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    340 \u001b[0;31m    \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--exp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","ipdb> c\n","Seed:  0\n","Experiment folder: pixel_classifiers/Berlin_benchmark/datasetDDPM/999_11\n","Creating DDPM Feature Extractor...\n","Pretrained model is successfully loaded from checkpoints/ddpm/64x64_diffusion.pt\n","Preparing the train set for Berlin_benchmark...\n","Take first 742 images...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 742/742 [01:31<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["> \u001b[0;32m/content/drive/.shortcut-targets-by-id/1kM6vOx8unEcGbzN3nwcZDA1phB8UHd8_/diffusion_segmentation/ddpm-segmentation/train_qkv_berlin.py\u001b[0m(227)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n","\u001b[0;32m    225 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    226 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m--> 227 \u001b[0;31m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" ********* max_label {args['number_class']} *** ignore_label {args['ignore_label']} ***********\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    228 \u001b[0;31m    \u001b[0;31m#print(f\" *********************** Current number data {len(features)} ***********************\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    229 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","ipdb> c\n"," ********* max_label 8 *** ignore_label 0 ***********\n"," *********************** Current dataloader length 172 ***********************\n","Epoch :  5 iteration 1000 loss 0.06625241786241531 acc tensor(98.4375, device='cuda:0')\n","Epoch :  11 iteration 2000 loss 0.0524083711206913 acc tensor(98.4375, device='cuda:0')\n","*************** Break, Total iters, 2045 , at epoch 11 ***************\n","save to: pixel_classifiers/Berlin_benchmark/datasetDDPM/999_11/model_0.pth\n","Loading pretrained models...\n","Creating DDPM Feature Extractor...\n","Pretrained model is successfully loaded from checkpoints/ddpm/64x64_diffusion.pt\n","Take first 742 images...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 742/742 [01:29<00:00,  8.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["save the predcitons lables to pixel_classifiers/Berlin_benchmark/datasetDDPM/999_11/predictions\n","saving 0th file \n","saving 100th file \n","saving 200th file \n","saving 300th file \n","saving 400th file \n","saving 500th file \n","saving 600th file \n","saving 700th file \n","Save inference map topixel_classifiers/Berlin_benchmark/datasetDDPM/999_11/visualizations/inference_map.jpg \n","Per-Class Metrics:\n","Forest -   Recall: 0.1983, Precision: 0.1219,F1 Score: 0.1510, IoU: 0.0817\n","Residential Area -   Recall: 0.2757, Precision: 0.5875,F1 Score: 0.3753, IoU: 0.2310\n","Industrial Area -   Recall: 0.1821, Precision: 0.0447,F1 Score: 0.0718, IoU: 0.0372\n","Low Plants -   Recall: 0.0669, Precision: 0.1050,F1 Score: 0.0817, IoU: 0.0426\n","Soil -   Recall: 0.1127, Precision: 0.0537,F1 Score: 0.0727, IoU: 0.0377\n","Allotment -   Recall: 0.0964, Precision: 0.0271,F1 Score: 0.0423, IoU: 0.0216\n","Commercial Area -   Recall: 0.0631, Precision: 0.0546,F1 Score: 0.0585, IoU: 0.0301\n","Water -   Recall: 0.0443, Precision: 0.0133,F1 Score: 0.0205, IoU: 0.0104\n","Overall accuracy: 0.2104\n","AA: 0.1299\n","Kappa Coefficient: 0.0032\n","Mean IoU: 0.0615\n","Mean F1 Score: 0.1092\n"]}],"source":["%run train_qkv_berlin.py --exp experiments/Berlin_benchmark/datasetDDPM.json $MODEL_FLAGS"]},{"cell_type":"markdown","metadata":{"id":"2cKofUbcebaM"},"source":["# Hyperspectral Augsburg Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJNjbu8QejQd"},"outputs":[],"source":["MODEL_FLAGS=\"--attention_resolutions 32,16,8 --class_cond True --diffusion_steps 1000 --dropout 0.1 --image_size 64 --learn_sigma True --noise_schedule cosine --num_channels 192 --num_head_channels 64 --num_res_blocks 3 --resblock_updown True --use_new_attention_order True --use_fp16 True --use_scale_shift_norm True\"\n","#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":721},"executionInfo":{"elapsed":3907,"status":"ok","timestamp":1721260488906,"user":{"displayName":"hutuhehe","userId":"18298293410951222141"},"user_tz":300},"id":"shDKBdCIehLW","outputId":"2dd23100-be0e-47c3-d87d-62dcfd91a31b"},"outputs":[{"output_type":"stream","name":"stdout","text":["> \u001b[0;32m/content/drive/MyDrive/diffusion_segmentation/ddpm-segmentation/train_qkv_berlin.py\u001b[0m(338)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m    336 \u001b[0;31m    \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    337 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m--> 338 \u001b[0;31m    \u001b[0madd_dict_to_argparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_and_diffusion_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    339 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    340 \u001b[0;31m    \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--exp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","ipdb> c\n","Seed:  0\n","Experiment folder: pixel_classifiers/Augsburg_Benchmark/datasetDDPM/0_10\n","Loading pretrained models...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Error(s) in loading state_dict for pixel_classifier:\n\tMissing key(s) in state_dict: \"layers.0.weight\", \"layers.0.bias\", \"layers.2.weight\", \"layers.2.bias\", \"layers.2.running_mean\", \"layers.2.running_var\", \"layers.3.weight\", \"layers.3.bias\", \"layers.5.weight\", \"layers.5.bias\", \"layers.5.running_mean\", \"layers.5.running_var\", \"layers.6.weight\", \"layers.6.bias\". \n\tUnexpected key(s) in state_dict: \"alpha\", \"beta\", \"spatial_processor.0.weight\", \"spatial_processor.0.bias\", \"spatial_processor.1.weight\", \"spatial_processor.1.bias\", \"spatial_processor.1.running_mean\", \"spatial_processor.1.running_var\", \"spatial_processor.1.num_batches_tracked\", \"spectral_processor.0.weight\", \"spectral_processor.0.bias\", \"spectral_processor.1.weight\", \"spectral_processor.1.bias\", \"spectral_processor.1.running_mean\", \"spectral_processor.1.running_var\", \"spectral_processor.1.num_batches_tracked\", \"spectral_processor.4.weight\", \"spectral_processor.4.bias\", \"spectral_processor.5.weight\", \"spectral_processor.5.bias\", \"spectral_processor.5.running_mean\", \"spectral_processor.5.running_var\", \"spectral_processor.5.num_batches_tracked\", \"spectral_processor.9.weight\", \"spectral_processor.9.bias\", \"spectral_processor.10.weight\", \"spectral_processor.10.bias\", \"spectral_processor.10.running_mean\", \"spectral_processor.10.running_var\", \"spectral_processor.10.num_batches_tracked\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.1.running_mean\", \"classifier.1.running_var\", \"classifier.1.num_batches_tracked\", \"classifier.3.weight\", \"classifier.3.bias\". ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/content/drive/MyDrive/diffusion_segmentation/ddpm-segmentation/train_qkv_berlin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading pretrained models...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/diffusion_segmentation/ddpm-segmentation/src/pixel_classifier.py\u001b[0m in \u001b[0;36mload_ensemble\u001b[0;34m(args, device)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;31m#model = Conv1D_Classfier(num_classes= args['number_class'],bands_num = args['bands_num']) # if using Conv1d classfier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2190\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for pixel_classifier:\n\tMissing key(s) in state_dict: \"layers.0.weight\", \"layers.0.bias\", \"layers.2.weight\", \"layers.2.bias\", \"layers.2.running_mean\", \"layers.2.running_var\", \"layers.3.weight\", \"layers.3.bias\", \"layers.5.weight\", \"layers.5.bias\", \"layers.5.running_mean\", \"layers.5.running_var\", \"layers.6.weight\", \"layers.6.bias\". \n\tUnexpected key(s) in state_dict: \"alpha\", \"beta\", \"spatial_processor.0.weight\", \"spatial_processor.0.bias\", \"spatial_processor.1.weight\", \"spatial_processor.1.bias\", \"spatial_processor.1.running_mean\", \"spatial_processor.1.running_var\", \"spatial_processor.1.num_batches_tracked\", \"spectral_processor.0.weight\", \"spectral_processor.0.bias\", \"spectral_processor.1.weight\", \"spectral_processor.1.bias\", \"spectral_processor.1.running_mean\", \"spectral_processor.1.running_var\", \"spectral_processor.1.num_batches_tracked\", \"spectral_processor.4.weight\", \"spectral_processor.4.bias\", \"spectral_processor.5.weight\", \"spectral_processor.5.bias\", \"spectral_processor.5.running_mean\", \"spectral_processor.5.running_var\", \"spectral_processor.5.num_batches_tracked\", \"spectral_processor.9.weight\", \"spectral_processor.9.bias\", \"spectral_processor.10.weight\", \"spectral_processor.10.bias\", \"spectral_processor.10.running_mean\", \"spectral_processor.10.running_var\", \"spectral_processor.10.num_batches_tracked\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.1.running_mean\", \"classifier.1.running_var\", \"classifier.1.num_batches_tracked\", \"classifier.3.weight\", \"classifier.3.bias\". "]}],"source":["\n","%run train_qkv_berlin.py --exp experiments/Augsburg_Benchmark/datasetDDPM.json $MODEL_FLAGS"]},{"cell_type":"markdown","metadata":{"id":"V0e5EZAo-fzp"},"source":["# Hyperspectral Berlin Dataset"]},{"cell_type":"markdown","metadata":{"id":"Vl6EYv09DD5a"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cD6sSctP-r3_"},"outputs":[],"source":["MODEL_FLAGS=\"--attention_resolutions 32,16,8 --class_cond True --diffusion_steps 1000 --dropout 0.1 --image_size 64 --learn_sigma True --noise_schedule cosine --num_channels 192 --num_head_channels 64 --num_res_blocks 3 --resblock_updown True --use_new_attention_order True --use_fp16 True --use_scale_shift_norm True\"\n","#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5330,"status":"ok","timestamp":1720557948025,"user":{"displayName":"luoboking","userId":"07792047166576627299"},"user_tz":300},"id":"JXPHiH-n-ssG","outputId":"d9b43c8b-fe94-4b47-f4f5-7dd3b85369dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["> \u001b[0;32m/content/drive/.shortcut-targets-by-id/1kM6vOx8unEcGbzN3nwcZDA1phB8UHd8_/diffusion_segmentation/ddpm-segmentation/train_qkv_berlin.py\u001b[0m(345)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m    343 \u001b[0;31m    \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    344 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m--> 345 \u001b[0;31m    \u001b[0madd_dict_to_argparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_and_diffusion_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    346 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[0;32m    347 \u001b[0;31m    \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--exp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\n","ipdb> c\n","Seed:  0\n","Experiment folder: pixel_classifiers/Berlin_64_label_adjust/datasetDDPM/50_150_250_2_3_4_7\n","Loading pretrained models...\n"]},{"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for DualPathNetwork:\n\tMissing key(s) in state_dict: \"alpha\", \"beta\", \"spatial_processor.layers.0.weight\", \"spatial_processor.layers.0.bias\", \"spatial_processor.layers.2.weight\", \"spatial_processor.layers.2.bias\", \"spatial_processor.layers.2.running_mean\", \"spatial_processor.layers.2.running_var\", \"spatial_processor.layers.3.weight\", \"spatial_processor.layers.3.bias\", \"spatial_processor.layers.5.weight\", \"spatial_processor.layers.5.bias\", \"spatial_processor.layers.5.running_mean\", \"spatial_processor.layers.5.running_var\", \"spatial_processor.layers.6.weight\", \"spatial_processor.layers.6.bias\", \"spectral_processor.conv1.weight\", \"spectral_processor.conv1.bias\", \"spectral_processor.bn1.weight\", \"spectral_processor.bn1.bias\", \"spectral_processor.bn1.running_mean\", \"spectral_processor.bn1.running_var\", \"spectral_processor.conv2.weight\", \"spectral_processor.conv2.bias\", \"spectral_processor.bn2.weight\", \"spectral_processor.bn2.bias\", \"spectral_processor.bn2.running_mean\", \"spectral_processor.bn2.running_var\", \"spectral_processor.fc.weight\", \"spectral_processor.fc.bias\". \n\tUnexpected key(s) in state_dict: \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.1.running_mean\", \"classifier.1.running_var\", \"classifier.1.num_batches_tracked\", \"classifier.3.weight\", \"classifier.3.bias\", \"spatial_processor.0.weight\", \"spatial_processor.0.bias\", \"spatial_processor.2.weight\", \"spatial_processor.2.bias\", \"spatial_processor.2.running_mean\", \"spatial_processor.2.running_var\", \"spatial_processor.2.num_batches_tracked\", \"spatial_processor.3.weight\", \"spatial_processor.3.bias\", \"spatial_processor.5.weight\", \"spatial_processor.5.bias\", \"spatial_processor.5.running_mean\", \"spatial_processor.5.running_var\", \"spatial_processor.5.num_batches_tracked\", \"spectral_processor.0.weight\", \"spectral_processor.0.bias\", \"spectral_processor.1.weight\", \"spectral_processor.1.bias\", \"spectral_processor.1.running_mean\", \"spectral_processor.1.running_var\", \"spectral_processor.1.num_batches_tracked\", \"spectral_processor.4.weight\", \"spectral_processor.4.bias\", \"spectral_processor.5.weight\", \"spectral_processor.5.bias\", \"spectral_processor.5.running_mean\", \"spectral_processor.5.running_var\", \"spectral_processor.5.num_batches_tracked\", \"spectral_processor.9.weight\", \"spectral_processor.9.bias\", \"spectral_processor.10.weight\", \"spectral_processor.10.bias\", \"spectral_processor.10.running_mean\", \"spectral_processor.10.running_var\", \"spectral_processor.10.num_batches_tracked\". ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1kM6vOx8unEcGbzN3nwcZDA1phB8UHd8_/diffusion_segmentation/ddpm-segmentation/train_qkv_berlin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading pretrained models...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m     \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1kM6vOx8unEcGbzN3nwcZDA1phB8UHd8_/diffusion_segmentation/ddpm-segmentation/src/pixel_classifier.py\u001b[0m in \u001b[0;36mload_ensemble\u001b[0;34m(args, device)\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;31m#model = Conv1D_Classfier(num_classes= args['number_class'],bands_num = args['bands_num']) # if using Conv1d classfier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2190\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DualPathNetwork:\n\tMissing key(s) in state_dict: \"alpha\", \"beta\", \"spatial_processor.layers.0.weight\", \"spatial_processor.layers.0.bias\", \"spatial_processor.layers.2.weight\", \"spatial_processor.layers.2.bias\", \"spatial_processor.layers.2.running_mean\", \"spatial_processor.layers.2.running_var\", \"spatial_processor.layers.3.weight\", \"spatial_processor.layers.3.bias\", \"spatial_processor.layers.5.weight\", \"spatial_processor.layers.5.bias\", \"spatial_processor.layers.5.running_mean\", \"spatial_processor.layers.5.running_var\", \"spatial_processor.layers.6.weight\", \"spatial_processor.layers.6.bias\", \"spectral_processor.conv1.weight\", \"spectral_processor.conv1.bias\", \"spectral_processor.bn1.weight\", \"spectral_processor.bn1.bias\", \"spectral_processor.bn1.running_mean\", \"spectral_processor.bn1.running_var\", \"spectral_processor.conv2.weight\", \"spectral_processor.conv2.bias\", \"spectral_processor.bn2.weight\", \"spectral_processor.bn2.bias\", \"spectral_processor.bn2.running_mean\", \"spectral_processor.bn2.running_var\", \"spectral_processor.fc.weight\", \"spectral_processor.fc.bias\". \n\tUnexpected key(s) in state_dict: \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.1.running_mean\", \"classifier.1.running_var\", \"classifier.1.num_batches_tracked\", \"classifier.3.weight\", \"classifier.3.bias\", \"spatial_processor.0.weight\", \"spatial_processor.0.bias\", \"spatial_processor.2.weight\", \"spatial_processor.2.bias\", \"spatial_processor.2.running_mean\", \"spatial_processor.2.running_var\", \"spatial_processor.2.num_batches_tracked\", \"spatial_processor.3.weight\", \"spatial_processor.3.bias\", \"spatial_processor.5.weight\", \"spatial_processor.5.bias\", \"spatial_processor.5.running_mean\", \"spatial_processor.5.running_var\", \"spatial_processor.5.num_batches_tracked\", \"spectral_processor.0.weight\", \"spectral_processor.0.bias\", \"spectral_processor.1.weight\", \"spectral_processor.1.bias\", \"spectral_processor.1.running_mean\", \"spectral_processor.1.running_var\", \"spectral_processor.1.num_batches_tracked\", \"spectral_processor.4.weight\", \"spectral_processor.4.bias\", \"spectral_processor.5.weight\", \"spectral_processor.5.bias\", \"spectral_processor.5.running_mean\", \"spectral_processor.5.running_var\", \"spectral_processor.5.num_batches_tracked\", \"spectral_processor.9.weight\", \"spectral_processor.9.bias\", \"spectral_processor.10.weight\", \"spectral_processor.10.bias\", \"spectral_processor.10.running_mean\", \"spectral_processor.10.running_var\", \"spectral_processor.10.num_batches_tracked\". "]}],"source":["%run train_qkv_berlin.py --exp experiments/berlin_64_stride_32/datasetDDPM.json $MODEL_FLAGS"]},{"cell_type":"markdown","metadata":{"id":"XEPAtByGlSy8"},"source":["# hyperspectral UH dataset(64by 64model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DDlZ1Gb2W9q"},"outputs":[],"source":["MODEL_FLAGS=\"--attention_resolutions 32,16,8 --class_cond True --diffusion_steps 1000 --dropout 0.1 --image_size 64 --learn_sigma True --noise_schedule cosine --num_channels 192 --num_head_channels 64 --num_res_blocks 3 --resblock_updown True --use_new_attention_order True --use_fp16 True --use_scale_shift_norm True\"\n","#python classifier_sample.py $MODEL_FLAGS --classifier_scale 1.0 --classifier_path models/64x64_classifier.pt --classifier_depth 4 --model_path models/64x64_diffusion.pt $SAMPLE_FLAGS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ro0gYLoWmgO3"},"outputs":[],"source":["%run train_qkv_berlin.py --exp experiments/berlin_64_stride_32/datasetDDPM.json $MODEL_FLAGS"]},{"cell_type":"markdown","metadata":{"id":"wXObgMChuszk"},"source":["put jpg patches into one big mask label"]}],"metadata":{"colab":{"provenance":[{"file_id":"1QmclmJ9benW2-MeVXYJfGe-RCR6qUQOo","timestamp":1709946631359},{"file_id":"1N_NOVWZlImob2x6qKd0lXMtSKwuW6eWz","timestamp":1707018897318},{"file_id":"1kNeGtPvEuPTvbOgji51Wavp9x6K5RJzS","timestamp":1706151817039}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}